{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning distributed representations of words and sentences\n",
    "\n",
    "### Recent techniques\n",
    " * pre-trained word vectors\n",
    " * character-level CNN encoding\n",
    " * sub-word token representation (e.g byte encodings)\n",
    " * higher level linguistic features\n",
    "    * part of speech (POS) tags\n",
    "    * names entities\n",
    "    * dependency paths\n",
    "\n",
    "### Key abstractions for expressivity\n",
    "  * TokenIndexers\n",
    "    * generate indexed tensors for sentences in a different ways\n",
    "       * SingleIdTokenIndexer vs TokenCharactersIndexer\n",
    "  * TokenEmbedders\n",
    "    * transform that maps indexed tensors into embedding representation\n",
    "       * simple case : PyTorch Embedding layer\n",
    "       * complex case : token_character_encoders with applied CNN\n",
    "  * TextFieldEmbedders\n",
    "    * wrapper of set of TokenEmbedders\n",
    "    * Applies TokenEmbedders and Concatenates(and performs other operations) on their results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.fields import TextField\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers \\\n",
    "    import SingleIdTokenIndexer, TokenCharactersIndexer\n",
    "from allennlp.data.tokenizers import Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens\n",
    "words = ['All','the','cool','kids','use','character','embeddings','.']\n",
    "words2 = ['I','prefer','word2vec','thouhg','...']\n",
    "\n",
    "tokens1 = list(map(Token,words))\n",
    "tokens2 = list(map(Token,words2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_indexers\n",
    "\n",
    "token_indexers = {\"tokens\":SingleIdTokenIndexer(namespace='token_ids'),\n",
    "                  'characters': TokenCharactersIndexer(namespace='token_characters')}\n",
    "sentence = TextField(tokens1,token_indexers)\n",
    "sentence2 = TextField(tokens2,token_indexers)\n",
    "\n",
    "instance = Instance({\"sentence\":sentence})\n",
    "instance2 = Instance({\"sentence\":sentence2})\n",
    "\n",
    "instances = [instance,instance2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data import Vocabulary\n",
    "from allennlp.data.dataset import Batch\n",
    "\n",
    "# Vocabulary\n",
    "vocab = Vocabulary.from_instances(instances)\n",
    "\n",
    "# batch\n",
    "instances = Batch(instances)\n",
    "\n",
    "for instance in instances:\n",
    "    instance.index_fields(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Define the TokenEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.token_embedders \\\n",
    "    import Embedding, TokenCharactersEncoder\n",
    "\n",
    "# to define CNN applied character level embedder\n",
    "from allennlp.modules.seq2vec_encoders import CnnEncoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple word embedder\n",
    "word_embedding = Embedding(\n",
    "    num_embeddings=vocab.get_vocab_size(\"token_ids\"),\n",
    "    embedding_dim =3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " embedding (transfom) \n",
    "\n",
    "  - Input : tensor (batch_size,\n",
    "                    max_num_words_in_sentence, \n",
    "                    max_char_len_in_word) \n",
    "  - Output :tensor(batch_size,\n",
    "                    max_num_words_in_sentence, \n",
    "                    max_char_len_in_word,\n",
    "                    embedding_dim) \n",
    " cnn encoder \n",
    "  \n",
    "  - output : tensor (batch_size,\n",
    "                     max_num_word_in_sentence,\n",
    "                     num_filters * ngram_filter_sizes)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "char_embedding = Embedding(\n",
    "    num_embeddings=vocab.get_vocab_size(\"token_characters\"),\n",
    "    embedding_dim = 5)\n",
    "\n",
    "character_cnn = CnnEncoder(\n",
    "    embedding_dim = 5 , \n",
    "    num_filters=2,\n",
    "    output_dim=4)\n",
    "\n",
    "token_character_encoder = TokenCharactersEncoder(\n",
    "                                embedding = char_embedding,\n",
    "                                encoder = character_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Define the TextFieldEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BasicTextFieldEmbedder\n",
    "\n",
    "from allennlp.modules.text_field_embedders \\\n",
    "    import BasicTextFieldEmbedder\n",
    "\n",
    "\n",
    "text_field_embedder = BasicTextFieldEmbedder(\n",
    "                        {'tokens': word_embedding, \n",
    "                         'characters':token_character_encoder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's apply text_field_embedder to data and see what happens\n",
    "\n",
    "#Converted the indexed dataset into Pytorch Variables\n",
    "batch = Batch(instances)\n",
    "tensors = batch.as_tensor_dict(batch.get_padding_lengths())\n",
    "print(\"torch tensors for passing to a model: \\n\\n\", tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field_variables = tensors['sentence']\n",
    "\n",
    "embedded_text  = text_field_embedder(text_field_variables)\n",
    "\n",
    "dimensions = list(embedded_text.size())\n",
    "\n",
    "print(\"Post embedding with our TextFieldEmbedder: \")\n",
    "print(\"Batch Size : \", dimensions[0])\n",
    "print(\"Sentence Length : \" , dimensions[1])\n",
    "print(\"Embedding size : \",dimensions[2])\n",
    "\n",
    "print(\"Embedded Tensor : \\n\\n\",embedded_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
