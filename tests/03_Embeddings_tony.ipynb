{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning distributed representations of words and sentences\n",
    "\n",
    "### Recent techniques\n",
    " * pre-trained word vectors\n",
    " * character-level CNN encoding\n",
    " * sub-word token representation (e.g byte encodings)\n",
    " * higher level linguistic features\n",
    "    * part of speech (POS) tags\n",
    "    * names entities\n",
    "    * dependency paths\n",
    "\n",
    "### Key abstractions for expressivity\n",
    "  * TokenIndexers\n",
    "    * generate indexed tensors for sentences in a different ways\n",
    "       * SingleIdTokenIndexer vs TokenCharactersIndexer\n",
    "  * TokenEmbedders\n",
    "    * transform that maps indexed tensors into embedding representation\n",
    "       * simple case : PyTorch Embedding layer\n",
    "       * complex case : token_character_encoders with applied CNN\n",
    "  * TextFieldEmbedders\n",
    "    * wrapper of set of TokenEmbedders\n",
    "    * Applies TokenEmbedders and Concatenates(and performs other operations) on their results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.fields import TextField\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.token_indexers \\\n",
    "    import SingleIdTokenIndexer, TokenCharactersIndexer\n",
    "from allennlp.data.tokenizers import Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens\n",
    "words = ['All','the','cool','kids','use','character','embeddings','.']\n",
    "words2 = ['I','prefer','word2vec','thouhg','...']\n",
    "\n",
    "tokens1 = list(map(Token,words))\n",
    "tokens2 = list(map(Token,words2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token_indexers\n",
    "\n",
    "token_indexers = {\"tokens\":SingleIdTokenIndexer(namespace='token_ids'),\n",
    "                  'characters': TokenCharactersIndexer(namespace='token_characters')}\n",
    "sentence = TextField(tokens1,token_indexers)\n",
    "sentence2 = TextField(tokens2,token_indexers)\n",
    "\n",
    "instance = Instance({\"sentence\":sentence})\n",
    "instance2 = Instance({\"sentence\":sentence2})\n",
    "\n",
    "instances = [instance,instance2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 2953.74it/s]\n"
     ]
    }
   ],
   "source": [
    "from allennlp.data import Vocabulary\n",
    "from allennlp.data.dataset import Batch\n",
    "\n",
    "# Vocabulary\n",
    "vocab = Vocabulary.from_instances(instances)\n",
    "\n",
    "# batch\n",
    "instances = Batch(instances)\n",
    "\n",
    "for instance in instances:\n",
    "    instance.index_fields(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2. Define the TokenEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.token_embedders \\\n",
    "    import Embedding, TokenCharactersEncoder\n",
    "\n",
    "# to define CNN applied character level embedder\n",
    "from allennlp.modules.seq2vec_encoders import CnnEncoder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple word embedder\n",
    "word_embedding = Embedding(\n",
    "    num_embeddings=vocab.get_vocab_size(\"token_ids\"),\n",
    "    embedding_dim =3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " embedding (transfom) \n",
    "\n",
    "  - Input : tensor (batch_size,\n",
    "                    max_num_words_in_sentence, \n",
    "                    max_char_len_in_word) \n",
    "  - Output :tensor(batch_size,\n",
    "                    max_num_words_in_sentence, \n",
    "                    max_char_len_in_word,\n",
    "                    embedding_dim) \n",
    " cnn encoder \n",
    "  \n",
    "  - output : tensor (batch_size,\n",
    "                     max_num_word_in_sentence,\n",
    "                     num_filters * ngram_filter_sizes)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "char_embedding = Embedding(\n",
    "    num_embeddings=vocab.get_vocab_size(\"token_characters\"),\n",
    "    embedding_dim = 5)\n",
    "\n",
    "character_cnn = CnnEncoder(\n",
    "    embedding_dim = 5 , \n",
    "    num_filters=2,\n",
    "    output_dim=4)\n",
    "\n",
    "token_character_encoder = TokenCharactersEncoder(\n",
    "                                embedding = char_embedding,\n",
    "                                encoder = character_cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Define the TextFieldEmbedder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BasicTextFieldEmbedder\n",
    "\n",
    "from allennlp.modules.text_field_embedders \\\n",
    "    import BasicTextFieldEmbedder\n",
    "\n",
    "\n",
    "text_field_embedder = BasicTextFieldEmbedder(\n",
    "                        {'tokens': word_embedding, \n",
    "                         'characters':token_character_encoder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch tensors for passing to a model: \n",
      "\n",
      " {'sentence': {'tokens': tensor([[ 2,  3,  4,  5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14,  0,  0,  0]]), 'characters': tensor([[[16,  9,  9,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [10,  4,  2,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 5,  6,  6,  9,  0,  0,  0,  0,  0,  0],\n",
      "         [17, 12,  7, 11,  0,  0,  0,  0,  0,  0],\n",
      "         [13, 11,  2,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 5,  4, 14,  3, 14,  5, 10,  2,  3,  0],\n",
      "         [ 2, 18, 19,  2,  7,  7, 12, 20, 15, 11],\n",
      "         [ 8,  0,  0,  0,  0,  0,  0,  0,  0,  0]],\n",
      "\n",
      "        [[21,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [22,  3,  2, 23,  2,  3,  0,  0,  0,  0],\n",
      "         [24,  6,  3,  7, 25, 26,  2,  5,  0,  0],\n",
      "         [10,  4,  6, 13,  4, 15,  0,  0,  0,  0],\n",
      "         [ 8,  8,  8,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]]])}}\n"
     ]
    }
   ],
   "source": [
    "# let's apply text_field_embedder to data and see what happens\n",
    "\n",
    "#Converted the indexed dataset into Pytorch Variables\n",
    "batch = Batch(instances)\n",
    "tensors = batch.as_tensor_dict(batch.get_padding_lengths())\n",
    "print(\"torch tensors for passing to a model: \\n\\n\", tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post embedding with our TextFieldEmbedder: \n",
      "Batch Size :  2\n",
      "Sentence Length :  8\n",
      "Embedding size :  7\n",
      "Embedded Tensor : \n",
      "\n",
      " tensor([[[ 0.1963, -0.3375,  0.1647, -0.1156, -0.0404, -0.5156,  0.3331],\n",
      "         [ 0.2908, -0.3940,  0.1887, -0.2405,  0.2811,  0.4906, -0.4056],\n",
      "         [ 0.2478, -0.3705,  0.1714, -0.2411,  0.1916,  0.5432, -0.4662],\n",
      "         [ 0.2789, -0.2663,  0.1470, -0.1924, -0.3673, -0.1278, -0.1605],\n",
      "         [ 0.3105, -0.3436,  0.2232, -0.2375, -0.0165,  0.5044,  0.0403],\n",
      "         [ 0.3064, -0.3487,  0.1801, -0.2848,  0.2411,  0.0355, -0.4371],\n",
      "         [ 0.3322, -0.3074,  0.2398, -0.2993, -0.0436,  0.0939, -0.0668],\n",
      "         [ 0.1526, -0.3271,  0.1999, -0.0636, -0.1979,  0.5730, -0.5436]],\n",
      "\n",
      "        [[ 0.1510, -0.3281,  0.2023, -0.0854,  0.5091, -0.3519,  0.0300],\n",
      "         [ 0.3827, -0.3614,  0.2198, -0.2577,  0.4955, -0.1582,  0.4972],\n",
      "         [ 0.2264, -0.2860,  0.2286, -0.2553, -0.5514,  0.1500,  0.0608],\n",
      "         [ 0.2022, -0.3576,  0.1423, -0.1917, -0.3281, -0.2090, -0.3172],\n",
      "         [ 0.1926, -0.3345,  0.2395, -0.0484,  0.3383,  0.4665, -0.3779],\n",
      "         [ 0.1526, -0.3271,  0.1998, -0.0634,  0.1804, -0.1773, -0.0530],\n",
      "         [ 0.1526, -0.3271,  0.1998, -0.0634,  0.1804, -0.1773, -0.0530],\n",
      "         [ 0.1526, -0.3271,  0.1998, -0.0634,  0.1804, -0.1773, -0.0530]]],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "text_field_variables = tensors['sentence']\n",
    "\n",
    "embedded_text  = text_field_embedder(text_field_variables)\n",
    "\n",
    "dimensions = list(embedded_text.size())\n",
    "\n",
    "print(\"Post embedding with our TextFieldEmbedder: \")\n",
    "print(\"Batch Size : \", dimensions[0])\n",
    "print(\"Sentence Length : \" , dimensions[1])\n",
    "print(\"Embedding size : \",dimensions[2])\n",
    "\n",
    "print(\"Embedded Tensor : \\n\\n\",embedded_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
