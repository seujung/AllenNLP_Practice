{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMO : Deep contextualized word representations\n",
    "\n",
    "Pre-trained contextual representations of words from large scale bidirectional languate models provides large improvements over GloVe / word2ved baselines.\n",
    "\n",
    "### Application includes:\n",
    "* question answering\n",
    "* co-reference \n",
    "* semantic role labeling \n",
    "* classification \n",
    "* syntcatic parsing\n",
    "\n",
    "### Reference \n",
    "* [Deep contextualized word representations](http://www.aclweb.org/anthology/N18-1202)\n",
    "* [AllenNLP ELMo section](https://allennlp.org/elmo)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual representation\n",
    "\n",
    "The elmo command will write all the BiLM individual layer representations for a dataset of senteneces to an HDF5 file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-02-07 12:43:52,738 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
      "2019-02-07 12:43:52,738 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
      "2019-02-07 12:43:52,741 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
      "2019-02-07 12:43:52,743 - INFO - allennlp.common.registrable - instantiating registered subclass relu of <class 'allennlp.nn.activations.Activation'>\n",
      "2019-02-07 12:43:52,808 - INFO - allennlp.commands.elmo - Initializing ELMo.\n",
      "2019-02-07 12:44:07,110 - INFO - allennlp.commands.elmo - Processing sentences.\n",
      "2it [00:00,  4.77it/s]\n"
     ]
    }
   ],
   "source": [
    "!allennlp elmo sentences.txt elmo_layers.hdf5 --all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the contextual representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers :  3\n",
      "Total number of words in the first sentence :  16\n",
      "Dimension of representation :  1024\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "h5py_file = h5py.File(\"elmo_layers.hdf5\",'r')\n",
    "embedding = h5py_file.get(\"0\")\n",
    "print(\"Total number of layers : \", len(embedding))\n",
    "print(\"Total number of words in the first sentence : \", \n",
    "      len(embedding[0]))\n",
    "print(\"Dimension of representation : \" , len(embedding[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ELMo as a PyTorch Module for fine-tuning\n",
    "\n",
    "#### allennlp.modules.elmo.Elmo class\n",
    "   Allows to compute weighted ELMo representations as PyTorch Tensor\n",
    "   \n",
    "   ![](elmo_eq.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "\n",
    "options_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "\n",
    "# Compute 2 different representation for each token.\n",
    "elmo = Elmo(options_file, weight_file, 2, dropout=0)\n",
    "\n",
    "# Convert sentences to character ids\n",
    "sentences = [['First','sentence', '.'], ['Another','.']]\n",
    "character_ids = batch_to_ids(sentences)\n",
    "\n",
    "embeddings = elmo(character_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output embedding of size \n",
      " \n",
      " - batch_size=2 \n",
      " - sequence_length=3 \n",
      " - ELMo vector size=1024\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = embeddings['elmo_representations'][0].size()\n",
    "print(\"The output embedding of size \\n\", \n",
    "      \"\\n - batch_size={}\".format(embedding_dim[0]), \n",
    "      \"\\n - sequence_length={}\".format(embedding_dim[1]), \n",
    "      \"\\n - ELMo vector size={}\".format(embedding_dim[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ELMo interactively\n",
    "\n",
    "#### allennlp.commands.elmo.ElmoEmbedder\n",
    "   - Provides easy way to process sentences with ELMo using Jupyter.\n",
    "   - 1st layer --> context insensitive token representation\n",
    "   - 2nd, 3rd  --> LSTM layers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.commands.elmo import ElmoEmbedder\n",
    "elmo = ElmoEmbedder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"I\", \"ate\", \"an\", \"apple\", \"for\", \"breakfast\"]\n",
    "vectors = elmo.embed_sentence(tokens)\n",
    "\n",
    "assert(len(vectors) == 3) # 3 layers, 1 for each layer\n",
    "assert(len(vectors[0] == len(tokens))) # each word return a vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6675608456134796"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "vectors2 = elmo.embed_sentence([\"I\",\"ate\",\"carrot\", \"for\", \"breakfact\"])\n",
    "scipy.spatial.distance.cosine(vectors[2][3],vectors2[2][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELMo as existing allennlp models\n",
    "\n",
    "#### Let's see how to add ELMo to existing model \n",
    "  - Adding single layer --> only configuration chage\n",
    "  - Adding two or more layers --> need to chage the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
